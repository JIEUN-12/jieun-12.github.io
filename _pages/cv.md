---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

ğŸ“š Education
======
* Ph.D in Computer Science, Yonsei University, 2025
  * Completed via Integrated M.S./Ph.D. Program
* B.S. in Computer Science and Engineering, Incheon University, South Korea, 2019

Project experiences
======
* Mar 2019 - Dec 2024: (SW starlab) Research and development of the high performance in-memory distributed DBMS based on flash memory storage in an IoT environment
  * Institute of Information & communications Technology Planning & Evaluation (IITP)
  * 2021-2023: Project Manager
  * 2019-2020, 2024: Research Member
  
Skills
======
* Related to DBMS or Data Systems
  * Auto-Tuning
  * Vector Databases
  * NoSQL and RDBMS (e.g., RocksDB, Spark, Redis, MySQL, and PostgreSQL)
* Bayesian Optimization
* Text-to-SQL
* Large Language Models (LLMs)
* Machine Learning
* Deep Learning

Publications
======
* LitE-SQL: A Lightweight and Efficient Text-to-SQL Framework with Vector-based Schema Linking and Execution-Guided Self-Correction. Shengmin Piao*, **Jieun Lee***, Sanghyun Park. **ArXiv, 2025** [ğŸ“–](https://arxiv.org/abs/2510.09014)
* An Efficient and Noise-Robust Framework for High-Dimensional Tuning in Big Data Analytics. **Jieun Lee***, Sangmin Seo, Chanho Yeom, Huijun Jin, Sein Kwon, Sanghyun Park. **_Engineering Applications of Artificial Intelligence_, 2025** [ğŸ“–](https://doi.org/10.1016/j.engappai.2025.111332)
* Towards Workload-Specific Configuration Tuning via Meta-Learning for RocksDB. Chanho Yeom*, **Jieun Lee***, Sangmin Seo, and Sanghyun Park. **(SMC 2024)** [ğŸ“–](https://doi.org/10.1109/SMC54092.2024.10831422)
* K2vTune: A workload-aware configuration tuning for RocksDB. **Jieun Lee***, Sangmin Seo, Jonghwan Choi, and Sanghyun Park. **_Information Processing & Management_, 2024** [ğŸ“–](https://doi.org/10.1016/j.ipm.2023.103567)
* ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ì„ ìœ„í•œ ë‹¤ì¤‘ ê´€ì ì„ ê°€ì§„ ìê°€ êµì—´ íŠ¸ëœìŠ¤í¬ë¨¸. **ì´ì§€ì€***, ë°•ì§„ìš±, ë°•ìƒí˜„. **_ì •ë³´ê³¼í•™íšŒë…¼ë¬¸ì§€_**, 2021
* Transformer ë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±. **ì´ì§€ì€***, ë°•ì§„ìš±, ë°•ì°¬í¬, í™ì •ìˆ˜, ë°•ìƒí˜„. **(KSC2019)**
